# Proposal Review: Catalyst Exposed: The Real Impact of 200 Funded Projects

**Proposal ID:** 1759
**Proposer:** Soraya Ponce
**Requested Funds:** 60,000 ADA
**Project Duration:** 6 months
**Theme:** Governance

## Summary
This proposal seeks to conduct the first large-scale, statistically rigorous offline study of 200 completed Catalyst projects (Funds 1-14), evaluating real-world adoption, sustainability, and barriers, and publishing a transparent report with recommendations to improve Catalyst governance and efficiency.

## Scores

### Impact ⭐ 4
High governance impact potential. Addresses legitimate community concerns about Catalyst ROI, project outcomes, and accountability. 200-project sample with 95% confidence level and ±4.9% margin of error (using stratified sampling) provides credible statistical rigor. If delivered, creates first evidence-based assessment of Catalyst effectiveness, informing future funding decisions and process improvements. Findings could strengthen Catalyst's reputation by demonstrating transparency and willingness to learn from failures. Report will be public, replicable, and actionable for Fund16+ improvements.

### Feasibility ⭐ 4
Strong feasibility signals. Team lead Soraya Ponce has documented Catalyst community involvement and event organization experience. Hiring professional statistician for sampling methodology ensures rigor. Approach is sound: stratified random sampling, 300 surveys, offline data collection, statistical analysis. Timeline is reasonable (6 months). Methodology is clearly explained with mathematical justification (Cochran formula for finite populations). Budget allocates appropriately to statistician (25,000 ADA) and data analysis. Risks are acknowledged (e.g., incomplete data from some projects) with mitigations (80% target for complete data).

### Value for Money ⭐ 4
60,000 ADA for first systematic audit of Catalyst outcomes is excellent value. Budget breakdown: 15,000 ADA data collection, 25,000 ADA statistician + market research firm + surveys, 10,000 ADA report + dissemination, 5,000 ADA webinar + community engagement, 3,000 ADA project management, 2,000 ADA contingency. Allocation is professional and realistic. Hiring external statistician and market research firm ensures credibility and reduces bias. Comparable World Bank or EU grant audits cost far more. If proposal delivers rigorous, actionable findings, value to ecosystem is multiples of investment. Cost per project analyzed (~300 ADA) is reasonable.

## Strengths
- Addresses critical governance need: accountability and learning from funded projects
- Statistically rigorous methodology (stratified sampling, 95% confidence, ±4.9% margin)
- Hiring professional statistician and market research firm ensures credibility
- Transparent approach: all data, methodology, and findings published on GitHub (MIT/CC-BY)
- Explicit commitment to "no blame" approach focused on systemic improvement
- Clear success metrics (200 projects, 80% complete data, 300 surveys, 75% satisfaction)
- Reasonable budget aligned with professional research standards
- Team has Catalyst community experience (Soraya Ponce + Emilica Calvache)
- Educational webinar planned to share findings

## Concerns
- Success depends on response rate from past funded teams (may be low if teams are defunct)
- 80% complete data target may be ambitious given some teams have disappeared
- No mention of independent peer review of methodology before execution
- Webinar target (150 participants) seems low for importance of findings
- Minor: Budget for "AI-based support tools for formatting" (in dissemination) is vague
- Study focuses on completed projects (Funds 1-14); active projects (Fund15+) excluded
- Risk of selection bias if only responsive teams participate (could skew positive)
- No plan to update study annually for longitudinal tracking

## Recommendation
**FUND** - This is one of the strongest governance proposals in the current fund. Addresses legitimate community concerns with scientific rigor and transparency. Team is competent, methodology is sound, budget is justified, and outputs will directly inform Catalyst improvements. The "no blame, collaborative learning" ethos is appropriate. Minor improvements: (1) commit to independent peer review of methodology by academic or governance expert, (2) increase webinar promotion to target 300+ participants, (3) address selection bias risk by sampling non-responsive teams differently, and (4) consider annual follow-up study for longitudinal data. Strong recommend to fund.
